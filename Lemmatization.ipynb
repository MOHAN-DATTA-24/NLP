{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPf1FqhyKpYKG6lZomvTrEr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MOHAN-DATTA-24/NLP/blob/main/Lemmatization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# using ***nltk***"
      ],
      "metadata": {
        "id": "f6DwPnVjPFBL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Wordnet Lemmatizer**\n",
        "Lemmatization technique is like stemming. The output we will get after lemmatization is called ‘lemma’, which is a root word rather than root stem, the output of stemming. After lemmatization, we will be getting a valid word that means the same thing.\n",
        "\n",
        "NLTK provides WordNetLemmatizer class which is a thin wrapper around the wordnet corpus. This class uses morphy() function to the WordNet CorpusReader class to find a lemma. Let us understand it with an example −\n"
      ],
      "metadata": {
        "id": "8ofAdu0yT21V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"wordnet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDvc8ZbPKMUa",
        "outputId": "bb2a0d50-640b-4d15-fc6d-48ab3ff9d02f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "vcmF2hh-Tn1U"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_net_lemma = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "954P6ygSJ1gL"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_net_lemma.lemmatize(\"history\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Ps8nrjuNJ2DJ",
        "outputId": "21804227-9c2e-4678-e8d0-382954194932"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'history'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatize word using WordNet's built-in morphy function.<br>\n",
        "**Returns the input word unchanged if it cannot be found in WordNet.**\n",
        "\n",
        "**POS**: The Part Of Speech tag. Valid options are <br>\n",
        "## pos = \"n\" for nouns,\n",
        "## pos = \"v\" for verbs,\n",
        "## pos = \"a\" for adjectives,\n",
        "## pos = \"r\" for adverbs and\n",
        "## pos = \"s\" for satellite adjectives.\n",
        "\n",
        "return: The lemma of word, for the given pos.\n",
        "\n",
        "**By default pos =\"n\" so for\n",
        "<br>going ---> O/p will be going<br> since it is considered as noun.**"
      ],
      "metadata": {
        "id": "zNtJWAitLLVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_net_lemma.lemmatize(\"going\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Oq7h6lmqMc1p",
        "outputId": "d0b2fb2e-43d9-44da-8544-2b2398cc0eae"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'going'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_net_lemma.lemmatize(\"going\",pos='v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5r1KPc__KytB",
        "outputId": "5f916136-d203-4194-e71e-d49df1a52eda"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'go'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]"
      ],
      "metadata": {
        "id": "JF4eqewyKd7q"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word+\"---->\"+word_net_lemma.lemmatize(word,pos=\"v\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypffVD-GJ2Ai",
        "outputId": "b40be4ab-ca8e-4296-afc4-af9d86c24313"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating---->eat\n",
            "eats---->eat\n",
            "eaten---->eat\n",
            "writing---->write\n",
            "writes---->write\n",
            "programming---->program\n",
            "programs---->program\n",
            "history---->history\n",
            "finally---->finally\n",
            "finalized---->finalize\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_net_lemma.lemmatize(\"fairly\",pos=\"r\"),word_net_lemma.lemmatize(\"sportingly\",pos=\"r\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y73O_zbkJ19y",
        "outputId": "baae70ac-f6cb-4c8e-e895-3259a50de836"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fairly', 'sportingly')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wordnet lemmatizer takes more time compared to stemming.\n",
        "\n",
        "APPlications are:<br>\n",
        "**Q&A, chatbots, text summarization**"
      ],
      "metadata": {
        "id": "A7UKaF8pNXrh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "<meta charset=\"UTF-8\">\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<h2>Disadvantages of Lemmatization</h2>\n",
        "\n",
        "<ul>\n",
        "    <li><strong>Computational Overhead:</strong> Lemmatization requires more computational resources compared to stemming due to dictionary lookups and morphological analysis.</li>\n",
        "    <li><strong>Dependency on Language Resources:</strong> Lemmatization relies heavily on comprehensive and accurate language resources, which may be lacking for less common languages or specialized domains.</li>\n",
        "    <li><strong>Context Sensitivity:</strong> Lemmatization considers word context, leading to potential ambiguity in determining the base form, especially for words with multiple meanings or forms.</li>\n",
        "</ul>\n",
        "\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "7CWUFjVpOh3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "<meta charset=\"UTF-8\">\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "<title>Stemming vs Lemmatization</title>\n",
        "<style>\n",
        "    table {\n",
        "        border-collapse: collapse;\n",
        "        width: 100%;\n",
        "    }\n",
        "    th, td {\n",
        "        border: 1px solid #dddddd;\n",
        "        text-align: left;\n",
        "        padding: 8px;\n",
        "    }\n",
        "    th {\n",
        "        background-color: #f2f2f2;\n",
        "    }\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<h2>Stemming vs Lemmatization</h2>\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <th>Feature</th>\n",
        "        <th>Stemming</th>\n",
        "        <th>Lemmatization</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Process</td>\n",
        "        <td>Reduces words to their root or base form by removing suffixes.</td>\n",
        "        <td>Determines the dictionary form or lemma of a word based on its intended meaning.</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Output</td>\n",
        "        <td>May produce non-existent words or stems that are not lexicographically correct.</td>\n",
        "        <td>Always produces valid words or lemmas.</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Complexity</td>\n",
        "        <td>Simple and faster compared to lemmatization.</td>\n",
        "        <td>More complex and slower due to dictionary lookups and morphological analysis.</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Accuracy</td>\n",
        "        <td>Less accurate compared to lemmatization as it may result in ambiguity or loss of meaning.</td>\n",
        "        <td>More accurate as it considers the context and meaning of words.</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Examples</td>\n",
        "        <td>Running -> Run, Books -> Book</td>\n",
        "        <td>Running -> Running, Books -> Book</td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "y0hqJOwFOOJR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# using ***spaCy***"
      ],
      "metadata": {
        "id": "HnI8Y8P0O-_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load English tokenizer, tagger, parser, and NER\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Given text\n",
        "text = \"The cats are chasing mice and jumping over fences.\"\n",
        "\n",
        "# Process the text with spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Lemmatize each token in the text\n",
        "lemmas = [token.lemma_ for token in doc]\n",
        "\n",
        "# Print the lemmas\n",
        "print(\"Original text:\", text)\n",
        "print(\"Lemmatized text:\", \" \".join(lemmas))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6AeBld1O5QY",
        "outputId": "56bbe8f9-46f6-4cbf-9c75-b0d9d2cb8ce6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: The cats are chasing mice and jumping over fences.\n",
            "Lemmatized text: the cat be chase mouse and jump over fence .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp(\"fairly\")[0].lemma_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "57VdZG1hPT8K",
        "outputId": "8f98807c-7c42-4d8f-946f-01e43d40d081"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fairly'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}